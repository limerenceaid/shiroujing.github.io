<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Jon Barron</title>

    <meta name="author" content="Shirou Jing">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/faceicom.jpg" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p class="name" style="text-align: center;">
                    Shirou Jing
                  </p>
                  <p>I'm a junior student at <a href="https://deepmind.google/">University of Chinese Academy of Science</a> in Beijing, majored in computer science, \
                    where I lead a small team that mostly works on <a href="https://www.matthewtancik.com/nerf">NeRF</a>.
                  </p>
                  <p>
                    I'm also an exchange student at UC Berkeley <a href="https://www.google.com/glass/start/">Glass</a>,  <a href="https://ai.googleblog.com/2014/04/lens-blur-in-new-google-camera-app.html">Lens Blur</a>, <a href="https://ai.googleblog.com/2014/10/hdr-low-light-and-high-dynamic-range.html">HDR+</a>, <a href="https://blog.google/products/google-ar-vr/introducing-next-generation-jump/">VR</a>, <a href="https://ai.googleblog.com/2017/10/portrait-mode-on-pixel-2-and-pixel-2-xl.html">Portrait Mode</a>, <a href="https://ai.googleblog.com/2020/12/portrait-light-enhancing-portrait.html">Portrait Light</a>, and <a href="https://blog.google/products/maps/three-maps-updates-io-2022/">Maps</a>. I did my PhD at <a href="http://www.eecs.berkeley.edu/">UC Berkeley</a>, where I was advised by <a href="http://www.cs.berkeley.edu/~malik/">Jitendra Malik</a>. I've received the <a href="https://www.thecvf.com/?page_id=413#YRA">PAMI Young Researcher Award</a>.
                  </p>
                  <p style="text-align:center">
                    <a href="mailto:shirou_sav@berkeley.edu">Email</a> &nbsp;/&nbsp;
                    <a href="data/CV-ShirouJing_formal.pdf">CV</a> &nbsp;/&nbsp;
                    <!-- <a href="data/JonBarron-bio.txt">Bio</a> &nbsp;/&nbsp; -->
                    <a href="https://scholar.google.com/citations?hl=en&user=jktWnL8AAAAJ">Scholar</a> &nbsp;/&nbsp;
                    <!-- <a href="https://twitter.com/jon_barron">Twitter</a> &nbsp;/&nbsp; -->
                    <a href="https://www.linkedin.com/in/shirou-jing-23056a303/">LinkedIn</a> &nbsp;/&nbsp;
                    <a href="https://github.com/limerenceaid">Github</a>
                  </p>
                </td>
                <td style="padding:2.5%;width:40%;max-width:40%">
                  <a href="images/Shirou.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/JonBarron.jpg" class="hoverZoomLink"></a>
                </td>
              </tr>
            </tbody>
          </table>
        
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Research Interest</h2>
                <p>
                  Generative Models, Image and Video Generation using Deep Learning, Integrating AI with Human needs, Human-Computer Interaction. I aim at using computer science and AI to create valuable innovations for society.
                </p>

                <p>

                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


      <tr onmouseout="cat3d_stop()" onmouseover="cat3d_start()" bgcolor="#ffffd0">
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
            <div class="two" id='cat3d_image'><video  width=100% height=100% muted autoplay loop>
            <source src="images/cat3d.mp4" type="video/mp4">
            Your browser does not support the video tag.
            </video></div>
            <img src='images/cat3d.jpg' width="160">
          </div>
          <script type="text/javascript">
            function cat3d_start() {
              document.getElementById('cat3d_image').style.opacity = "1";
            }

            function cat3d_stop() {
              document.getElementById('cat3d_image').style.opacity = "0";
            }
            cat3d_stop()
          </script>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://cat3d.github.io/">
        <span class="papertitle">CAT3D: Create Anything in 3D with Multi-View Diffusion Models
  </span>
          </a>
          <br>
          <a href="https://ruiqigao.github.io/">Ruiqi Gao</a>*,
          <a href="https://holynski.org/">Aleksander Holynski</a>*, 
          <a href="https://henzler.github.io/">Philipp Henzler</a>,
          <a href="https://github.com/ArthurBrussee">Arthur Brussee</a>, 
          <a href="http://ricardomartinbrualla.com/">Ricardo Martin Brualla</a>, 
          <a href="https://pratulsrinivasan.github.io/">Pratul P. Srinivasan</a>,
          <strong>Jonathan T. Barron</strong>,
          <a href="https://poolio.github.io/">Ben Poole</a>*

          <br>
          <em>arXiv</em>, 2024
          <br>
          <a href="https://cat3d.github.io/">project page</a>
          /
          <a href="https://arxiv.org/abs/2405.10314">arXiv</a>
          <p></p>
          <p>
          A single model built around diffusion and NeRF that does text-to-3D, image-to-3D, and few-view reconstruction, trains in 1 minute, and renders at 60FPS in a browser.
          </p>
        </td>
      </tr>



      <tr onmouseout="smerf_stop()" onmouseover="smerf_start()">
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
            <div class="two" id='smerf_image'><video  width=100% muted autoplay loop>
            <source src="images/smerf.mp4" type="video/mp4">
            Your browser does not support the video tag.
            </video></div>
            <img src='images/smerf.jpg' width=100%>
          </div>
          <script type="text/javascript">
            function smerf_start() {
              document.getElementById('smerf_image').style.opacity = "1";
            }

            function smerf_stop() {
              document.getElementById('smerf_image').style.opacity = "0";
            }
            smerf_stop()
          </script>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://smerf-3d.github.io/">
            <span class="papertitle">SMERF: Streamable Memory Efficient Radiance Fields for Real-Time Large-Scene Exploration</span>
          </a>
          <br>
      <a href="http://www.stronglyconvex.com/about.html">Daniel Duckworth*</a>,
      <a href="https://phogzone.com/">Peter Hedman*</a>,
      <a href="https://creiser.github.io/">Christian Reiser</a>,
      <a href="">Peter Zhizhin</a>,
      <a href="">Jean-François Thibert</a>,
          <a href="https://lucic.ai/">Mario Lučić</a>,
          <a href="https://szeliski.org/">Richard Szeliski</a>,
      <strong>Jonathan T. Barron</strong>
          <br>
          <em>SIGGRAPH</em>, 2024 &nbsp <font color="red"><strong>(Honorable Mention)</strong></font>
          <br>
          <a href="https://smerf-3d.github.io/">project page</a>
          /
          <a href="https://www.youtube.com/watch?v=zhO8iUBpnCc">video</a>
          /
          <a href="https://arxiv.org/abs/2312.07541">arXiv</a>
          <p></p>
          <p>
          Distilling a Zip-NeRF into a tiled set of MERFs lets you fly through radiance fields on laptops and smartphones at 60 FPS.
          </p>
        </td>
      </tr>
    

      <tr onmouseout="nuvo_stop()" onmouseover="nuvo_start()">
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
            <div class="two" id='nuvo_image'><video  width=100% muted autoplay loop>
            <source src="images/nuvo.mp4" type="video/mp4">
            Your browser does not support the video tag.
            </video></div>
            <img src='images/nuvo.jpg' width=100%>
          </div>
          <script type="text/javascript">
            function nuvo_start() {
              document.getElementById('nuvo_image').style.opacity = "1";
            }

            function nuvo_stop() {
              document.getElementById('nuvo_image').style.opacity = "0";
            }
            nuvo_stop()
          </script>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://pratulsrinivasan.github.io/nuvo/">
            <span class="papertitle">Nuvo: Neural UV Mapping for Unruly 3D Representations</span>
          </a>
          <br>
          <a href="https://pratulsrinivasan.github.io/">Pratul Srinivasan</a>,
          <a href="http://stephangarbin.com/">Stephan J. Garbin</a>,
          <a href="https://dorverbin.github.io/">Dor Verbin</a>,
      <strong>Jonathan T. Barron</strong>,
          <a href="https://bmild.github.io/">Ben Mildenhall</a>
          <br>
          <em>arXiv</em>, 2023
          <br>
          <a href="https://pratulsrinivasan.github.io/nuvo/">project page</a>
          /
          <a href="https://www.youtube.com/watch?v=hmJiOSTDQZI">video</a>
          /
          <a href="http://arxiv.org/abs/2312.05283">arXiv</a>
          <p></p>
          <p>
          Neural fields let you recover editable UV mappings for the challenging geometries produced by NeRF-like models.
          </p>
        </td>
      </tr>

      <tr onmouseout="mira_stop()" onmouseover="mira_start()">
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
            <div class="two" id='mira_image'>
              <img src='images/mira_after.jpg' width="160"></div>
            <img src='images/mira_before.jpg' width="160">
          </div>
          <script type="text/javascript">
            function mira_start() {
              document.getElementById('mira_image').style.opacity = "1";
            }

            function mira_stop() {
              document.getElementById('mira_image').style.opacity = "0";
            }
            mira_stop()
          </script>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://openreview.net/forum?id=AmPeAFzU3a4">
            <span class="papertitle">MIRA: Mental Imagery for Robotic Affordances</span>
          </a>
          <br>
          <a href="https://yenchenlin.me/">Lin Yen-Chen</a>, 
          <a href="http://www.peteflorence.com/">Pete Florence</a>, 
          <a href="https://andyzeng.github.io/">Andy Zeng</a>, <strong>Jonathan T. Barron</strong>, 
          <a href="https://yilundu.github.io/">Yilun Du</a>,
          <a href="https://people.csail.mit.edu/weichium/">Wei-Chiu Ma</a>,
          <a href="https://anthonysimeonov.github.io/">Anthony Simeonov</a>,
          <a href="https://meche.mit.edu/people/faculty/ALBERTOR@MIT.EDU">Alberto Rodriguez</a>,
          <a href="http://web.mit.edu/phillipi/">Phillip Isola</a>
          <br>
          <em>CoRL</em>, 2022
          <p></p>
          <p>
            NeRF lets us synthesize novel orthographic views that work well with pixel-wise algorithms for robotic manipulation.
          </p>
        </td>
      </tr>		

      <tr onmouseout="rgbd_stop()" onmouseover="rgbd_start()">
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div id='rgbd_anim' class='hidden'><img src="images/SceneSIRFS.gif"></div>
          <div id='rgbd_still'><img src="images/SceneSIRFS-still.jpg"></div>
          <script type="text/javascript">
            function rgbd_start() {
              document.getElementById('rgbd_anim').style.display = 'inline';
              document.getElementById('rgbd_still').style.display = 'none';
            }

            function rgbd_stop() {
              document.getElementById('rgbd_anim').style.display = 'none';
              document.getElementById('rgbd_still').style.display = 'inline';
            }
            rgbd_stop()
          </script>
        </td>
        <td width="75%" valign="middle">
          <a href="https://drive.google.com/file/d/1snypSLhzC0jXCchJRsWpcDZ7Es5hDmXo/view?usp=sharing">
            <span class="papertitle">Intrinsic Scene Properties from a Single RGB-D Image</span>
          </a>
          <br>
          <strong>Jonathan T. Barron</strong>, <a href="http://www.cs.berkeley.edu/~malik/">Jitendra Malik</a>
          <br>
          <em>CVPR</em>, 2013 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
          <br>
          <a href="https://drive.google.com/file/d/1cLUw72WpgdZ_3TQAjJABdgywqjBfn_Mq/view?usp=sharing">supplement</a> / <a href="data/BarronMalikCVPR2013.bib">bibtex</a> / <a href="http://techtalks.tv/talks/intrinsic-scene-properties-from-a-single-rgb-d-image/58614/">talk</a> / <a href="https://drive.google.com/file/d/0B4nuwEMaEsnmWW1CZGJPbi12R0k/view?usp=sharing">keynote</a> (or <a href="https://drive.google.com/file/d/19q3EFf6GIb4UFcCN2DVU2jVKpxRj5kxf/view?usp=sharing">powerpoint</a>, <a href="https://drive.google.com/file/d/0B4nuwEMaEsnmMzQ4ZVp1SWdnVkk/view?usp=sharing">PDF</a>) / <a href="https://drive.google.com/open?id=1ZbPScVA6Efqd-ESvojl92sw8K-82Xxry">code &amp; data</a>
          <p>By embedding mixtures of shapes &amp; lights into a soft segmentation of an image, and by leveraging the output of the Kinect, we can extend SIRFS to scenes.
            <br>
            <br>TPAMI Journal version: <a href="https://drive.google.com/file/d/1iQiUxZvjPPnb8rFCwXYesTgFSRk7mkAq/view?usp=sharing">version</a> / <a href="data/BarronMalikTPAMI2015B.bib">bibtex</a>
          </p>
        </td>
      </tr>

          </tbody></table>

          
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
            <tr>
              <td>
                <h2>Miscellanea</h2>
              </td>
            </tr>
          </tbody></table>
          <table width="100%" align="center" border="0" cellpadding="20"><tbody>
            
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle"><img src="images/cvf.jpg"></td>
              <td width="75%" valign="center">
                <a href="https://cvpr.thecvf.com/Conferences/2024/Organizers">Area Chair, CVPR 2024</a>
                <br>
                <a href="https://cvpr2023.thecvf.com/Conferences/2023/Organizers">Demo Chair, CVPR 2023</a>
                <br>
                <a href="https://cvpr2022.thecvf.com/area-chairs">Area Chair, CVPR 2022</a>
                <br>
                <a href="http://cvpr2021.thecvf.com/area-chairs">Area Chair & Award Committee Member, CVPR 2021</a>
                <br>
                <a href="http://cvpr2019.thecvf.com/area_chairs">Area Chair, CVPR 2019</a>
                <br>
                <a href="http://cvpr2018.thecvf.com/organizers/area_chairs">Area Chair, CVPR 2018</a>
              </td>
            </tr>
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/cs188.jpg" alt="cs188">
              </td>
              <td width="75%" valign="center">
                <a href="http://inst.eecs.berkeley.edu/~cs188/sp11/announcements.html">Graduate Student Instructor, CS188 Spring 2011</a>
                <br>
                <a href="http://inst.eecs.berkeley.edu/~cs188/fa10/announcements.html">Graduate Student Instructor, CS188 Fall 2010</a>
                <br>
                <a href="http://aima.cs.berkeley.edu/">Figures, "Artificial Intelligence: A Modern Approach", 3rd Edition</a>
              </td>
            </tr>
            

            <tr>
              <td align="center" style="padding:20px;width:25%;vertical-align:middle">
                <h2>Basically <br> Blog Posts</h2>
              </td>
              <td width="75%" valign="middle">
                <a href="https://arxiv.org/abs/2112.11687">Squareplus: A Softplus-Like Algebraic Rectifier</a>
                <br>
                <a href="https://arxiv.org/abs/2010.09714">A Convenient Generalization of Schlick's Bias and Gain Functions</a>
                <br>
                <a href="https://arxiv.org/abs/1704.07483">Continuously Differentiable Exponential Linear Units</a>
                <br>
                <a href="https://jonbarron.info/data/cvpr2023_llm_workshop_annotated.pdf">Scholars & Big Models: How Can Academics Adapt?</a>
              </td>
            </tr>
            
            
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  Feel free to steal this website's <a href="https://github.com/jonbarron/jonbarron_website">source code</a>. <strong>Do not</strong> scrape the HTML from this page itself, as it includes analytics tags that you do not want on your own website &mdash; use the github code instead. Also, consider using <a href="https://leonidk.com/">Leonid Keselman</a>'s <a href="https://github.com/leonidk/new_website">Jekyll fork</a> of this page.
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>